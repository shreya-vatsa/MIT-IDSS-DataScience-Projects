{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXQzH0nC5JtP"
   },
   "source": [
    "# **Project: Amazon Product Recommendation System**\n",
    "\n",
    "# **Marks: 40**\n",
    "\n",
    "\n",
    "Welcome to the project on Recommendation Systems. We will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model. \n",
    "\n",
    "--------------\n",
    "## **Context:**\n",
    "--------------\n",
    "\n",
    "Today, information is growing exponentially with volume, velocity and variety throughout the globe. This has lead to information overload, and too many choices for the consumer of any business. It represents a real dilemma for these consumers and they often turn to denial. Recommender Systems are one of the best tools that help recommending products to consumers while they are browsing online. Providing personalized recommendations which is most relevant for the user is what's most likely to keep them engaged and help business. \n",
    "\n",
    "E-commerce websites like Amazon, Walmart, Target and Etsy use different recommendation models to provide personalized suggestions to different users. These companies spend millions of dollars to come up with algorithmic techniques that can provide personalized recommendations to their users.\n",
    "\n",
    "Amazon, for example, is well-known for its accurate selection of recommendations in its online site. Amazon's recommendation system is capable of intelligently analyzing and predicting customers' shopping preferences in order to offer them a list of recommended products. Amazon's recommendation algorithm is therefore a key element in using AI to improve the personalization of its website. For example, one of the baseline recommendation models that Amazon uses is item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n",
    "\n",
    "----------------\n",
    "## **Objective:**\n",
    "----------------\n",
    "\n",
    "You are a Data Science Manager at Amazon, and have been given the task of building a recommendation system to recommend products to customers based on their previous ratings for other products. You have a collection of labeled data of Amazon reviews of products. The goal is to extract meaningful insights from the data and build a recommendation system that helps in recommending products to online consumers.\n",
    "\n",
    "-----------------------------\n",
    "## **Dataset:** \n",
    "-----------------------------\n",
    "\n",
    "The Amazon dataset contains the following attributes:\n",
    "\n",
    "- **userId:** Every user identified with a unique id\n",
    "- **productId:** Every product identified with a unique id\n",
    "- **Rating:** The rating of the corresponding product by the corresponding user\n",
    "- **timestamp:** Time of the rating. We **will not use this column** to solve the current problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmdPxJ2Q7W7p"
   },
   "source": [
    "**Note:** The code has some user defined functions that will be usefull while making recommendations and measure model performance, you can use these functions or can create your own functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoRfgjS2yekq"
   },
   "source": [
    "**Note:** This notebook uses the `surprise` library for building recommendation systems. Install it using:\n",
    "```bash\n",
    "pip install scikit-surprise\n",
    "```\n",
    "\n",
    "The dataset is located in the `data/` folder of this project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing surprise library \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05HQoiZYlsbB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surpriseNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "     ---------------------------------------- 0.0/154.4 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 20.5/154.4 kB 217.9 kB/s eta 0:00:01\n",
      "     --------- --------------------------- 41.0/154.4 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 154.4/154.4 kB 1.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\thene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-surprise) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\thene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\thene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-surprise) (1.12.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml): started\n",
      "  Building wheel for scikit-surprise (pyproject.toml): finished with status 'error'\n",
      "Failed to build scikit-surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for scikit-surprise (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [155 lines of output]\n",
      "      C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "      \n",
      "              By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        corresp(dist, value, root_dir)\n",
      "      C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist._finalize_license_expression()\n",
      "      C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\accuracy.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\builtin_datasets.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\dataset.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\dump.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\reader.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\trainset.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\utils.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\__init__.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\__main__.py -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      creating build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\search.py -> build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\split.py -> build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\validation.py -> build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "      copying surprise\\model_selection\\__init__.py -> build\\lib.win-amd64-cpython-311\\surprise\\model_selection\n",
      "      creating build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\algo_base.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\baseline_only.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\knns.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\predictions.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\random_pred.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\__init__.py -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      running egg_info\n",
      "      writing scikit_surprise.egg-info\\PKG-INFO\n",
      "      writing dependency_links to scikit_surprise.egg-info\\dependency_links.txt\n",
      "      writing entry points to scikit_surprise.egg-info\\entry_points.txt\n",
      "      writing requirements to scikit_surprise.egg-info\\requires.txt\n",
      "      writing top-level names to scikit_surprise.egg-info\\top_level.txt\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "      dependency C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\numpy\\core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "      reading manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no previously-included files matching '*.so' found under directory 'surprise'\n",
      "      adding license file 'LICENSE.md'\n",
      "      writing manifest file 'scikit_surprise.egg-info\\SOURCES.txt'\n",
      "      C:\\Users\\thene\\AppData\\Local\\Temp\\pip-build-env-quer93pl\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'surprise.prediction_algorithms' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'surprise.prediction_algorithms' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'surprise.prediction_algorithms' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'surprise.prediction_algorithms' to be distributed and are\n",
      "              already explicitly excluding 'surprise.prediction_algorithms' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      copying surprise\\similarities.c -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\similarities.pyx -> build\\lib.win-amd64-cpython-311\\surprise\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.c -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.c -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.c -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.c -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\co_clustering.pyx -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\matrix_factorization.pyx -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\optimize_baselines.pyx -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      copying surprise\\prediction_algorithms\\slope_one.pyx -> build\\lib.win-amd64-cpython-311\\surprise\\prediction_algorithms\n",
      "      running build_ext\n",
      "      building 'surprise.similarities' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-surprise\n",
      "ERROR: Could not build wheels for scikit-surprise, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\thene\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install scikit-surprise\n",
    "# For Windows users, if you encounter build errors, try:\n",
    "# Option 1: Install using conda (recommended for Windows)\n",
    "#   conda install -c conda-forge scikit-surprise\n",
    "# Option 2: Install Microsoft C++ Build Tools from:\n",
    "#   https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "# Option 3: Use pre-built wheel (if available for your Python version)\n",
    "#   pip install scikit-surprise --only-binary :all:\n",
    "\n",
    "%pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fIt4jcFIm76"
   },
   "source": [
    "## **Importing the necessary libraries and overview of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzu2P-TT5JtP"
   },
   "outputs": [],
   "source": [
    "import warnings                                 # Used to ignore the warning given as output of the code\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np                              # Basic libraries of python for numeric and dataframe computations\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt                 # Basic library for data visualization\n",
    "import seaborn as sns                           # Slightly advanced library for data visualization\n",
    "\n",
    "from collections import defaultdict             # A dictionary output that does not raise a key error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error  # A performance metrics in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrXYJAv95JtP"
   },
   "source": [
    "### **Loading the data**\n",
    "- Import the Dataset\n",
    "- Add column names ['user_id', 'prod_id', 'rating', 'timestamp']\n",
    "- Drop the column timestamp\n",
    "- Copy the data to another DataFrame called **df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGb-Hk1B5JtP"
   },
   "outputs": [],
   "source": [
    "# Import the Dataset (no headers in the CSV file)\n",
    "df = pd.read_csv('data/ratings_Electronics.csv', header=None)\n",
    "\n",
    "# Add column names\n",
    "df.columns = ['user_id', 'prod_id', 'rating', 'timestamp']\n",
    "\n",
    "# Drop the column timestamp\n",
    "df = df.drop('timestamp', axis=1)\n",
    "\n",
    "df_copy = df.copy(deep = True) # Copying the data to another DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVQnSG5g_9uX"
   },
   "source": [
    "**As this dataset is very large and has 7,824,482 observations, it is not computationally possible to build a model using this. Moreover, many users have only rated a few products and also some products are rated by very few users. Hence, we can reduce the dataset by considering certain logical assumptions.**\n",
    "\n",
    "Here, we will be taking users who have given at least 50 ratings, and the products that have at least 5 ratings, as when we shop online we prefer to have some number of ratings of a product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yt9W7Q32EQQ"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the users\n",
    "users = df.user_id\n",
    "\n",
    "# Create a dictionary from users to their number of ratings\n",
    "ratings_count = dict()\n",
    "\n",
    "for user in users:\n",
    "\n",
    "    # If we already have the user, just add 1 to their rating count\n",
    "    if user in ratings_count:        \n",
    "        ratings_count[user] += 1\n",
    "  \n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[user] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19XB60dq2EQR"
   },
   "outputs": [],
   "source": [
    "# We want our users to have at least 50 ratings to be considered\n",
    "RATINGS_CUTOFF = 50\n",
    "\n",
    "remove_users = []\n",
    "\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "\n",
    "df = df.loc[ ~ df.user_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33UzK1D82EQS"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the products\n",
    "prods = df.prod_id\n",
    "\n",
    "# Create a dictionary from products to their number of ratings\n",
    "ratings_count = dict()\n",
    "\n",
    "for prod in prods:\n",
    "    \n",
    "    # If we already have the product, just add 1 to its rating count\n",
    "    if prod in ratings_count:\n",
    "        ratings_count[prod] += 1\n",
    "    \n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[prod] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6YE-lUp2EQT"
   },
   "outputs": [],
   "source": [
    "# We want our item to have at least 5 ratings to be considered\n",
    "RATINGS_CUTOFF = 5\n",
    "\n",
    "remove_users = []\n",
    "\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "\n",
    "df_final = df.loc[~ df.prod_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aL1JZ00o5JtQ"
   },
   "outputs": [],
   "source": [
    "# Print a few rows of the imported dataset\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuPoy_XfxhXZ"
   },
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0d0bWeG-sVB"
   },
   "source": [
    "### **Shape of the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyBVTRDTyek0"
   },
   "source": [
    "### **Check the number of rows and columns and provide observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJ4eQKaY5JtQ"
   },
   "outputs": [],
   "source": [
    "# Check the number of rows and columns and provide observations\n",
    "shape = df_final.shape\n",
    "print(\"Number of rows:\", shape[0])\n",
    "print(\"Number of columns:\", shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Slp-fgWQ-sVD"
   },
   "source": [
    "Observation: There are 65290 rows and 3 columns in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAMWm0nC-sVF"
   },
   "source": [
    "### **Data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVrgMkye5JtQ"
   },
   "outputs": [],
   "source": [
    "# Check Data types and provide observations\n",
    "df_final.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4fOE02D-sVF"
   },
   "source": [
    "Observation: There are no null values present in dataframe. Rating is the only numerical column based on dtypes given above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTMpOROT-sVG"
   },
   "source": [
    "### **Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt-VEjMA5JtQ"
   },
   "outputs": [],
   "source": [
    "# Check for missing values present and provide observations\n",
    "df_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMWuBNhI5JtR"
   },
   "source": [
    "Observation: All the attributes have 0 null values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wETrCg48-sVG"
   },
   "source": [
    "### **Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYm30MXR5JtR"
   },
   "outputs": [],
   "source": [
    "# Summary statistics of 'rating' variable and provide observations\n",
    "df_final.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqW50EIJxhXc"
   },
   "source": [
    "Observation: The rating is the only numerical column to have the summary statistics. All the 50% 75% and max are given the rating of 5.0 Range is max - min = 4.0. IQR: 1.0. The mean is less than the median. The summary suggests that the ratings are positively skewed since the mean is less than the median, and a substantial number of ratings are at the maximum possible value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywyFrZIf5JtR"
   },
   "source": [
    "### **Checking the rating distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbqhbEVe-sVH"
   },
   "outputs": [],
   "source": [
    "# Create the bar plot and provide observations\n",
    "plt.figure(figsize = (12, 6))\n",
    "\n",
    "df_final['rating'].value_counts(1).plot(kind = 'bar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0jONrQv-sVH"
   },
   "source": [
    "Observation: The highest bar is for rating of 5.0, which suggests that it is the most common rating given. Its relative frequency exceeds 0.5, which implies that more than half of the ratings in the dataset are 5.0. There is a positive skew in the data, meaning there is a higher concentration of higher ratings. Counts have been normalized to show proportions rather than absolute counts by the command value_counts(1). Ratings 3 to 1 are the least occuring, suggesting that people give ratings for products they really like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HefpLdLJxhXd"
   },
   "source": [
    "### **Checking the number of unique users and items in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbSom7195JtR"
   },
   "outputs": [],
   "source": [
    "# Number of total rows in the data and number of unique user id and product id in the data\n",
    "print('The number of observations in the final data = ', len(df_final))\n",
    "print('Number of unique USERS in Raw data = ', df_final['user_id'].nunique())\n",
    "print('Number of unique ITEMS in Raw data = ', df_final['prod_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qwgz6CUt-sVI"
   },
   "source": [
    "Observation: There are 1540 unique users in the dataset. There are 5689 unique products in the dataset. As per the number of unique users and products, there is a possibility of 1540 * 5689 = 8,761,060 ratings in the dataset. But we only have 7,824,482 ratings, i.e., not every user has rated every product in the dataset. And we can build a recommendation system to recommend a product to users. Since the raw dataset was very large we are using the df_final dataset to build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfDnhSS4-sVI"
   },
   "source": [
    "### **Users with the most number of ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7MX452q5JtR"
   },
   "outputs": [],
   "source": [
    "# Top 10 users based on the number of ratings\n",
    "most_rated = df_final.groupby('user_id').size().sort_values(ascending = False)[:10]\n",
    "most_rated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X2w_jt9-sVI"
   },
   "source": [
    "Observation: The highest number of ratings by a user is 295 which is far from the actual number of products present in the data. We can build a recommendation system to recommend products to users which they have not interacted with. But still, there is a possibility of 5689 - 295 = 5394 more interactions as we have 5689 unique products in our dataset. For those remaining products, we can build a recommendation system to predict which product is likely to be rated by this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distributions of ratings for 295 interactions with given user_id\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "df_final[df_final['user_id'] == \"ADLVFFE4VBT8\"]['rating'].value_counts().plot(kind = 'bar')\n",
    "\n",
    "# Name the xlabel of the plot\n",
    "plt.xlabel('Rating')\n",
    "\n",
    "# Name the ylabel of the plot\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_rated_products = df_final.groupby('prod_id').size().sort_values(ascending = False)[:10]\n",
    "most_rated_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "The product with prod_id B0088CJT4U has been interacted with by most users which is 206 times.\n",
    "But still, there is a possibility of 1540-206 = 1334 more interactions as we have 1540 unique users in our dataset. For those remaining users, we can build a recommendation system to predict who is most likely to buy this product.\n",
    "Also, out of these 206 interactions, we need to consider the distribution of ratings as well to check whether this product is the most liked or most disliked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distributions of ratings for 295 interactions with given user_id\n",
    "plt.figure(figsize = (7, 7))\n",
    "\n",
    "df_final[df_final['prod_id'] == \"B0088CJT4U\"]['rating'].value_counts().plot(kind = 'bar')\n",
    "\n",
    "# Name the xlabel of the plot\n",
    "plt.xlabel('Rating')\n",
    "\n",
    "# Name the ylabel of the plot\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: The product is liked by majority of the users.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnYTx-Ol-sVg"
   },
   "source": [
    "**Now that we have explored and prepared the data, let's build the first recommendation system.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xYGrGVy5JtS"
   },
   "source": [
    "## **Model 1: Rank Based Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxZTj1UPxhXh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the average rating for each product\n",
    "avg_rating = df_final.groupby('prod_id')['rating'].mean()\n",
    "\n",
    "# Calculate the count of ratings for each product\n",
    "count_rating = df_final.groupby('prod_id')['rating'].count()\n",
    "\n",
    "# Create a dataframe with calculated average and count of ratings\n",
    "final_rating = pd.DataFrame({'avg_rating': avg_rating, 'rating_count': count_rating})\n",
    "# Sort the dataframe by average of ratings in the descending order\n",
    "final_rating = final_rating.sort_values(by='avg_rating', ascending=False)\n",
    "\n",
    "# See the first five records of the \"final_rating\" dataset\n",
    "final_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKU__5s1xhXi"
   },
   "outputs": [],
   "source": [
    "# Defining a function to get the top n products based on the highest average rating and minimum interactions\n",
    "def top_n_products(final_rating, n, min_interaction):\n",
    "\n",
    "    # Finding products with minimum number of interactions\n",
    "    recommendations = final_rating[final_rating['rating_count'] >= min_interaction]\n",
    "\n",
    "    # Sorting values with respect to average rating in descending order\n",
    "    recommendations = recommendations.sort_values(by='avg_rating', ascending=False)\n",
    "\n",
    "    return recommendations.head(n).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8l6373PxhXi"
   },
   "source": [
    "### **Recommending top 5 products with 50 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBxdLiM_xhXi"
   },
   "outputs": [],
   "source": [
    "list(top_n_products(final_rating, 5, 50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9_xW_UMxhXj"
   },
   "source": [
    "### **Recommending top 5 products with 100 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZgGZCUoxhXj"
   },
   "outputs": [],
   "source": [
    "list(top_n_products(final_rating, 5, 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL-m68a15JtT",
    "outputId": "69132b0f-8d3f-4798-f6a0-249e17a3c822"
   },
   "source": [
    "We have recommended the **top 5** products by using the popularity recommendation system. Now, let's build a recommendation system using **collaborative filtering.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJI5kiiGvOOK"
   },
   "source": [
    "## **Model 2: Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skzc0N1_nVNB"
   },
   "source": [
    "### **Building a baseline user-user similarity based recommendation system**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Uo_MYMnVNB"
   },
   "source": [
    "- Below, we are building **similarity-based recommendation systems** using `cosine` similarity and using **KNN to find similar users** which are the nearest neighbor to the given user.  \n",
    "- We will be using a new library, called `surprise`, to build the remaining models. Let's first import the necessary classes and functions from this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJ1wEylUpexj"
   },
   "outputs": [],
   "source": [
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# Class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# For tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# For splitting the rating data in train and test datasets\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# For implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# For implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# for implementing K-Fold cross-validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# For implementing clustering-based recommendation system\n",
    "from surprise import CoClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54MqVAtDTsnl"
   },
   "source": [
    "**Before building the recommendation systems, let's  go over some basic terminologies we are going to use:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qsxb3xhnTsnl"
   },
   "source": [
    "**Relevant item:** An item (product in this case) that is actually **rated higher than the threshold rating** is relevant, if the **actual rating is below the threshold then it is a non-relevant item**.  \n",
    "\n",
    "**Recommended item:** An item that's **predicted rating is higher than the threshold is a recommended item**, if the **predicted rating is below the threshold then that product will not be recommended to the user**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moyLUHCuTsnl"
   },
   "source": [
    "**False Negative (FN):** It is the **frequency of relevant items that are not recommended to the user**. If the relevant items are not recommended to the user, then the user might not buy the product/item. This would result in the **loss of opportunity for the service provider**, which they would like to minimize.\n",
    "\n",
    "**False Positive (FP):** It is the **frequency of recommended items that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant items to the user. This would result in **loss of resources for the service provider**, which they would also like to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yuvc2VaZTsnl"
   },
   "source": [
    "**Recall:** It is the **fraction of actually relevant items that are recommended to the user**, i.e., if out of 10 relevant products, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
    "\n",
    "**Precision:** It is the **fraction of recommended items that are relevant actually**, i.e., if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NLc36Y8Tsnm"
   },
   "source": [
    "**While making a recommendation system, it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are some most used performance metrics used in the assessment of recommendation systems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqF8fRBqTsnm"
   },
   "source": [
    "### **Precision@k, Recall@ k, and F1-score@k**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imMJNF0HTsnm"
   },
   "source": [
    "**Precision@k** - It is the **fraction of recommended items that are relevant in `top k` predictions**. The value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  \n",
    "\n",
    "\n",
    "**Recall@k** - It is the **fraction of relevant items that are recommended to the user in `top k` predictions**.\n",
    "\n",
    "**F1-score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBW4BUhWTsnm"
   },
   "source": [
    "### **Some useful functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOBHKh0eTsnm"
   },
   "source": [
    "- Below function takes the **recommendation model** as input and gives the **precision@k, recall@k, and F1-score@k** for that model.  \n",
    "- To compute **precision and recall**, **top k** predictions are taken under consideration for each user.\n",
    "- We will use the precision and recall to compute the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rxn-GahOTsnm"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(model, k = 10, threshold = 3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    # Making predictions on the test data\n",
    "    predictions = model.test(testset)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key = lambda x: x[0], reverse = True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    # Mean of all the predicted precisions are calculated.\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
    "    \n",
    "    # Mean of all the predicted recalls are calculated.\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
    "    \n",
    "    accuracy.rmse(predictions)\n",
    "    \n",
    "    print('Precision: ', precision) # Command to print the overall precision\n",
    "    \n",
    "    print('Recall: ', recall) # Command to print the overall recall\n",
    "    \n",
    "    print('F_1 score: ', round((2*precision*recall)/(precision+recall), 3)) # Formula to compute the F-1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZmsamDVyek-"
   },
   "source": [
    "**Hints:**\n",
    "\n",
    "- To compute **precision and recall**, a **threshold of 3.5 and k value of 10 can be considered for the recommended and relevant ratings**.\n",
    "- Think about the performance metric to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hxjJMTwnVNB"
   },
   "source": [
    "Below we are loading the **`rating` dataset**, which is a **pandas DataFrame**, into a **different format called `surprise.dataset.DatasetAutoFolds`**, which is required by this library. To do this, we will be **using the classes `Reader` and `Dataset`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGfYDiOCpe4X"
   },
   "outputs": [],
   "source": [
    "# Instantiating Reader scale with expected rating scale\n",
    "reader = Reader(rating_scale = (0, 5))\n",
    "\n",
    "# Loading the rating dataset\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
    "\n",
    "# Splitting the data into train and test datasets\n",
    "trainset, testset = train_test_split(data, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmHTEt7TnVNC"
   },
   "source": [
    "Now, we are **ready to build the first baseline similarity-based recommendation system** using the cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVDfVHB4tQfU"
   },
   "source": [
    "### **Building the user-user Similarity-based Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO3FL7iape8A",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Declaring the similarity options\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True  # user-user similarity\n",
    "}\n",
    "\n",
    "# Initialize the KNNBasic model using sim_options declared, Verbose = False, and setting random_state = 1\n",
    "sim_user_user = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "sim_user_user.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above\n",
    "precision_recall_at_k(sim_user_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEuJK_A9Tsnn"
   },
   "source": [
    "Observation: An RMSE of 1.0012 suggests that the average prediction error is slightly over 20% of the full range of possible ratings (5 - 0 = 5). The RMSE value suggests that on average, the predicted ratings are about 1 point away from the actual ratings. Precision of 0.855 suggests that 85.5% of the items the system recommends are actually liked by the users. Out of all the recommended products 85.5% are relevant. The recall of 0.858 indicates that the system successfully retrieves a high proportion of the items that users are interested in. Out of all the relevant products, 85.8% are recommended. The F_1 score which is the harmonic mean of precision and recall, is 0.856. This suggests a system with both high precision and high recall. An F_1 score closer to 1 is indicative of a robust model. The model recommends items to a user based on the preferences of similar users. Cosine similarity is useful when you're more interested in the orientation (i.e., which items users like, regardless of the number of items rated) rather than the magnitude of ratings. Random_state=1 ensures that the results are reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reFD0-nsnVNC"
   },
   "source": [
    "Let's now **predict rating for a user with `userId=A3LDPF5FMB782Z` and `productId=1400501466`** as shown below. Here the user has already interacted or watched the product with productId '1400501466' and given a rating of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxd23bZ9pe_x"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with an interacted product\n",
    "sim_user_user.predict(\"A3LDPF5FMB782Z\", \"1400501466\", r_ui = 5, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJcqG_wemRH"
   },
   "source": [
    "Observation: : The actual rating provided by the user (r_ui) for the item is 5.0, the highest possible rating. The estimated rating (est) predicted is 3.4. Given the discrepancy between the estimated and actual ratings, the recommendation algorithm may need further tuning or additional information to improve its predictions. This might involve incorporating more user data, refining the model, or considering different algorithms or parameters. The model is underestimating the ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj6ecbglTsno"
   },
   "source": [
    "Below is the **list of users who have not seen the product with product id \"1400501466\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCRBMD-RTsno"
   },
   "outputs": [],
   "source": [
    "# Find unique user_id where prod_id is not equal to \"1400501466\"\n",
    "df_final[df_final.prod_id != \"1400501466\"].user_id.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT42ecaSTsno"
   },
   "source": [
    "* It can be observed from the above list that **user \"A34BZM6S9L7QI4\" has not seen the product with productId \"1400501466\"** as this userId is a part of the above list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXSgq8OEnVNE"
   },
   "source": [
    "**Below we are predicting rating for `userId=A34BZM6S9L7QI4` and `prod_id=1400501466`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbFcBj1PpfEV"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with a non interacted product\n",
    "sim_user_user.predict(\"A34BZM6S9L7QI4\", \"1400501466\", verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02rwld8yemRI"
   },
   "source": [
    "Observation: The system estimated a rating of 4.29 for this user-product pair. The details dictionary in the output contains the key was_impossible set to True, which signifies that a reliable prediction could not be made. The algorithm could not find a sufficient number of similar users to make a reliable prediction. Despite being marked as impossible, the system still provides an estimated rating which could be based on the global average, user average, item average, or some other default strategy when the user-item interaction data is not sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejjof6csnVNF"
   },
   "source": [
    "### **Improving similarity-based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2j4VvfQnVNF"
   },
   "source": [
    "Below, we will be tuning hyperparameters for the `KNNBasic` algorithm. Let's try to understand some of the hyperparameters of the KNNBasic algorithm:\n",
    "\n",
    "- **k** (int) – The (max) number of neighbors to take into account for aggregation. Default is 40.\n",
    "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.\n",
    "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise - \n",
    "    - cosine\n",
    "    - msd (default)\n",
    "    - Pearson\n",
    "    - Pearson baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LmPbSUSTsnp"
   },
   "outputs": [],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30],  # number of neighbors\n",
    "    'sim_options': {\n",
    "        'name': ['msd', 'cosine', 'pearson'],  # similarity measures to test\n",
    "        'user_based': [True, False]  # user-based or item-based collaborative filtering\n",
    "    }\n",
    "}\n",
    "\n",
    "# Performing 3-fold cross-validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Fitting the data\n",
    "gs.fit(data)\n",
    "# Best RMSE score\n",
    "print('Best RMSE score: ', gs.best_score['rmse'])\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "print('Best parameters: ', gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2fHNvu7nVNF"
   },
   "source": [
    "Once the grid search is **complete**, we can get the **optimal values for each of those hyperparameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHWgxu_YnVNG"
   },
   "source": [
    "Now, let's build the **final model by using tuned values of the hyperparameters**, which we received by using **grid search cross-validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PujRJA8X_JEJ"
   },
   "outputs": [],
   "source": [
    "# Using the optimal similarity measure for user-user based collaborative filtering\n",
    "sim_options = {\n",
    "    'name': 'msd',  # or 'cosine' or 'pearson', depending on your results\n",
    "    'user_based': True  # since we are doing user-user CF\n",
    "}\n",
    "\n",
    "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_user_user_optimized = KNNBasic(sim_options=sim_options, k=20, min_k=5, random_state=1, verbose=False)\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "sim_user_user_optimized.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k and recall@k also with k =10\n",
    "precision_recall_at_k(sim_user_user_optimized, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHsWvFjKTsnp"
   },
   "source": [
    "Observation: The F_1 score has increased from 0.856 to 0.87. RMSE is reduced from 1.0012 to 0.95. Precision has decreased while Recall has increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhcAXK0CnVNG"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgV63lHiq1TV"
   },
   "outputs": [],
   "source": [
    "# Use sim_user_user_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId 1400501466\n",
    "prediction_A3 = sim_user_user_optimized.predict(\"A3LDPF5FMB782Z\", \"1400501466\")\n",
    "print(\"Predicted rating for user A3LDPF5FMB782Z on product 1400501466:\", prediction_A3.est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXO2Ztjhq1bN"
   },
   "outputs": [],
   "source": [
    "# Use sim_user_user_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "prediction_A34 = sim_user_user_optimized.predict(\"A34BZM6S9L7QI4\", \"1400501466\")\n",
    "print(\"Predicted rating for user A34BZM6S9L7QI4 on product 1400501466:\", prediction_A34.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5i-OPprNF2e"
   },
   "source": [
    "Observation: The latter user is likely to give a lower rating to the product compared to the former. But the prediction of the latter user when compared to the baseline model remains the same, while the former user's prediction is increased from 3.4 to 4.849"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_zwO_FnVNH"
   },
   "source": [
    "### **Identifying similar users to a given user (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2QsfqhanVNH"
   },
   "source": [
    "We can also find out **similar users to a given user** or its **nearest neighbors** based on this KNNBasic algorithm. Below, we are finding the 5 most similar users to the first user in the list with internal id 0, based on the `msd` distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbFle7cKmBJG"
   },
   "outputs": [],
   "source": [
    "# 0 is the inner id of the above user\n",
    "sim_user_user_optimized.get_neighbors(0, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0NsrX_anVNH"
   },
   "source": [
    "### **Implementing the recommendation algorithm based on optimized KNNBasic model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ESobDynVNI"
   },
   "source": [
    "Below we will be implementing a function where the input parameters are:\n",
    "\n",
    "- data: A **rating** dataset\n",
    "- user_id: A user id **against which we want the recommendations**\n",
    "- top_n: The **number of products we want to recommend**\n",
    "- algo: the algorithm we want to use **for predicting the ratings**\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vW9V1Tk65HlY"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "    \n",
    "    # Creating an empty list to store the recommended product ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # Creating an user item interactions matrix \n",
    "    user_item_interactions_matrix = data.pivot(index = 'user_id', columns = 'prod_id', values = 'rating')\n",
    "    \n",
    "    # Extracting those product ids which the user_id has not interacted yet\n",
    "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "    \n",
    "    # Looping through each of the product ids which user_id has not interacted yet\n",
    "    for item_id in non_interacted_products:\n",
    "        \n",
    "        # Predicting the ratings for those non interacted product ids by this user\n",
    "        est = algo.predict(user_id, item_id).est\n",
    "        \n",
    "        # Appending the predicted ratings\n",
    "        recommendations.append((item_id, est))\n",
    "\n",
    "    # Sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    return recommendations[:top_n] # Returing top n highest predicted rating products for this user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj_S7kh4nVNI"
   },
   "source": [
    "**Predicting top 5 products for userId = \"A3LDPF5FMB782Z\" with similarity based recommendation system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWbR85mI5Hrk"
   },
   "outputs": [],
   "source": [
    "# Making top 5 recommendations for user_id \"A3LDPF5FMB782Z\" with a similarity-based recommendation engine\n",
    "recommendations = get_recommendations(df_final, \"A3LDPF5FMB782Z\", 5, sim_user_user_optimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5WfIX0Z6_q2"
   },
   "outputs": [],
   "source": [
    "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(recommendations, columns = ['prod_id', 'predicted_ratings'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgbzJKk7Tsnr"
   },
   "source": [
    "### **Item-Item Similarity-based Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTJu_2hcTsnr"
   },
   "source": [
    "* Above we have seen **similarity-based collaborative filtering** where similarity is calculated **between users**. Now let us look into similarity-based collaborative filtering where similarity is seen **between items**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5RMcdzjTsns",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Declaring the similarity options\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False  # False indicates item-item CF\n",
    "}\n",
    "\n",
    "# KNN algorithm is used to find desired similar items. Use random_state=1\n",
    "sim_item_item = KNNBasic(sim_options=sim_options, random_state=1, verbose=False)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the test set\n",
    "sim_item_item.fit(trainset)\n",
    "\n",
    "# Let us compute precision@k, recall@k, and f_1 score with k = 10\n",
    "precision_recall_at_k(sim_item_item, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni9LoeUVTsns"
   },
   "source": [
    "Observation: Item-Item Similarity: The recommendation system has been setup to calculate similarities between items (products), rather than between users. This is indicated by the user_based: False setting in the sim_options dictionary.The cosine similarity measure is used to calculate the similarity between items. The system uses a k-nearest neighbors algorithm (KNNBasic) for finding similar items. The random_state=1 parameter ensures reproducibility of results; k=10, which means that the top 10 recommendations for each user are considered.\n",
    "\n",
    "RMSE of the predictions is 0.9950, indicating that on average, the model's predicted ratings are about one point off from the actual ratings, which is a moderate error given the 0-5 rating scale. -Precision is 0.838, suggesting that 83.8% of the top 10 items recommended by the system are relevant to the users.\n",
    "Recall is 0.845, indicating that the system is able to identify 84.5% of the relevant items within the top 10 recommendations.\n",
    "The F_1 score, which is the harmonic mean of precision and recall, is 0.841, showing a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFbcDQmxTsns"
   },
   "source": [
    "Let's now **predict a rating for a user with `userId = A3LDPF5FMB782Z` and `prod_Id = 1400501466`** as shown below. Here the user has already interacted or watched the product with productId \"1400501466\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsF-aaWYTsns"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with an interacted product\n",
    "predicted_rating = sim_item_item.predict(\"A3LDPF5FMB782Z\", \"1400501466\")\n",
    "print(\"Estimated Rating:\", predicted_rating.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h0OyDMFTsns"
   },
   "source": [
    "Observation: The system expects the user to have a positive preference for this product, given that the rating is closer to the upper end of the rating scale (assuming a 0-5 scale). However this is lower than the rating predicted by the user-user similarity tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqKGZoAtTsns"
   },
   "source": [
    "Below we are **predicting rating for the `userId = A34BZM6S9L7QI4` and `prod_id = 1400501466`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yILOxXRTsns"
   },
   "outputs": [],
   "source": [
    "# Predicting rating for a sample user with a non interacted product\n",
    "predicted_rating = sim_item_item.predict(\"A34BZM6S9L7QI4\", \"1400501466\")\n",
    "print(\"Estimated Rating:\", predicted_rating.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDKaAveJTsns"
   },
   "source": [
    "Observation: This rating is similar to the one predicted in the earlier user-user model. And this user is likely to rate this product more than the previous user in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meSvpNLj_EjD"
   },
   "source": [
    "### **Hyperparameter tuning the item-item similarity-based model**\n",
    "- Use the following values for the param_grid and tune the model.\n",
    "  - 'k': [10, 20, 30]\n",
    "  - 'min_k': [3, 6, 9]\n",
    "  - 'sim_options': {'name': ['msd', 'cosine']\n",
    "  - 'user_based': [False]\n",
    "- Use GridSearchCV() to tune the model using the 'rmse' measure\n",
    "- Print the best score and best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5bcZ3HgTsnt"
   },
   "outputs": [],
   "source": [
    "# Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30],\n",
    "    'min_k': [3, 6, 9],\n",
    "    'sim_options': {\n",
    "        'name': ['msd', 'cosine'],\n",
    "        'user_based': [False]  # Ensure it's item-item CF\n",
    "    }\n",
    "}\n",
    "\n",
    "# Performing 3-fold cross validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# Find the best RMSE score\n",
    "print('Best RMSE score:', gs.best_score['rmse'])\n",
    "\n",
    "# Find the combination of parameters that gave the best RMSE score\n",
    "print('Best parameters:', gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1psOlx6zTsnt"
   },
   "source": [
    "Once the **grid search** is complete, we can get the **optimal values for each of those hyperparameters as shown above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrSTaQemTsnt"
   },
   "source": [
    "Now let's build the **final model** by using **tuned values of the hyperparameters** which we received by using grid search cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOS9Dwnd_LN6"
   },
   "source": [
    "### **Use the best parameters from GridSearchCV to build the optimized item-item similarity-based model. Compare the performance of the optimized model with the baseline model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSeiM1qeTsnt"
   },
   "outputs": [],
   "source": [
    "# Using the optimal similarity measure for item-item based collaborative filtering\n",
    "best_params = gs.best_params['rmse']\n",
    "sim_options = {\n",
    "    'name': best_params['sim_options']['name'],\n",
    "    'user_based': best_params['sim_options']['user_based']  # should be False for item-item CF\n",
    "}\n",
    "\n",
    "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "sim_item_item_optimized = KNNBasic(sim_options=sim_options, k=best_params['k'], min_k=best_params['min_k'], random_state=1, verbose=False)\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "sim_item_item_optimized.fit(trainset)\n",
    "\n",
    "\n",
    "# Let us compute precision@k and recall@k, f1_score and RMSE\n",
    "precision_recall_at_k(sim_item_item_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCXKnMI8Tsnt"
   },
   "source": [
    "Observation: Compared to the previous statistic: RMSE: 0.9950 Precision: 0.838 Recall: 0.845 F_1 score: 0.841\n",
    "\n",
    "The RMSE here is lesser than before. Recall is higher than 0.845 which was the predicted value in the last algorithm. model.F_1 score is greater than the score in the previous algorithm which was 0.841"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sbcj_H94Tsnt"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIBRRvdoTsnt"
   },
   "outputs": [],
   "source": [
    "# Use sim_item_item_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "optimized_prediction_A3 = sim_item_item_optimized.predict(\"A3LDPF5FMB782Z\", \"1400501466\")\n",
    "print(\"Optimized model predicted rating for A3LDPF5FMB782Z on product 1400501466:\", optimized_prediction_A3.est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sim_item_item_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "optimized_prediction_A34 = sim_item_item_optimized.predict(\"A34BZM6S9L7QI4\", \"1400501466\")\n",
    "print(\"Optimized model predicted rating for A34BZM6S9L7QI4 on product 1400501466:\", optimized_prediction_A34.est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: For the first user, the prediction is on the upper end. The second user has the same prediction as in the earlier model based on user-user similarity, and in the untuned model 2 algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDlNB7tnTsnu"
   },
   "source": [
    "### **Identifying similar items to a given item (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLdDiFA6Tsnu"
   },
   "source": [
    "We can also find out **similar items** to a given item or its nearest neighbors based on this **KNNBasic algorithm**. Below we are finding the 5 most similar items to the item with internal id 0 based on the `msd` distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRJS4oDFTsnu"
   },
   "outputs": [],
   "source": [
    "sim_item_item_optimized.get_neighbors(0, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting top 5 products for userId = \"A1A5KUIIIHFF4U\" with similarity based recommendation system.**\n",
    "\n",
    "**Hint:** Use the get_recommendations() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzoEbuZFTsnu"
   },
   "outputs": [],
   "source": [
    "# Making top 5 recommendations for user_id A1A5KUIIIHFF4U with similarity-based recommendation engine.\n",
    "recommendations = get_recommendations(df_final, \"A1A5KUIIIHFF4U\", 5, sim_item_item_optimized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kXVTiysTsnv"
   },
   "outputs": [],
   "source": [
    "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "pd.DataFrame(recommendations, columns = ['prod_id', 'predicted_ratings'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHzmYvs0Tsnv"
   },
   "source": [
    "Now as we have seen **similarity-based collaborative filtering algorithms**, let us now get into **model-based collaborative filtering algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKgJpSA9vOOL"
   },
   "source": [
    "### **Model 3: Model-Based Collaborative Filtering - Matrix Factorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF6ZGyqhCAob"
   },
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4Otha8ovOOL"
   },
   "source": [
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sGl3QkLvOOL"
   },
   "source": [
    "SVD is used to **compute the latent features** from the **user-item matrix**. But SVD does not work when we **miss values** in the **user-item matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07-2PT5Ssjqm"
   },
   "outputs": [],
   "source": [
    "# Using SVD matrix factorization. Use random_state = 1\n",
    "svd = SVD(random_state=1)\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "precision_recall_at_k(svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ6fTuCDnVNL"
   },
   "source": [
    "Observations:\n",
    "\n",
    "The RMSE is reduced (0.882). This is the least of both the models earlier indicating a better fit. The random_state=1 parameter ensures that the results are reproducible by initializing the random number generator to a fixed state.\n",
    "Here, precision is 0.853, which means that 85.3% of the items recommended by the model are relevant to the users.\n",
    "Recall measures the ratio of relevant items that are recommended. A recall of 0.88 indicates that the model recommends 88% of the items that are relevant to the users.\n",
    "The F_1 score here is 0.866, suggesting a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's now predict the rating for a user with `userId = \"A3LDPF5FMB782Z\"` and `prod_id = \"1400501466`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWIhfdxXsjqm"
   },
   "outputs": [],
   "source": [
    "# Making prediction\n",
    "svd.predict(\"A3LDPF5FMB782Z\", \"1400501466\", r_ui = 5, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIjzqDY5nVNM"
   },
   "source": [
    "Observation: Compared to model 2 this predicted value is lower and over 3.5 which still indicates a likelihood of positive preference. The prediction here is higher than model 1. The was_impossible is False which means the prediction is feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1aYxVeMnVNM"
   },
   "source": [
    "**Below we are predicting rating for the `userId = \"A34BZM6S9L7QI4\"` and `productId = \"1400501466\"`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APm-uMSvcAMf"
   },
   "outputs": [],
   "source": [
    "# Making prediction\n",
    "svd.predict(\"A34BZM6S9L7QI4\", \"1400501466\", verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEL6dy3wnVNM"
   },
   "source": [
    "Observations: The was_impossible is false so a prediction is feasible. The highest compared to both user-user and item-item based similarity. 4.4 is on the upper end of user preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x13Eb9Owvpcw"
   },
   "source": [
    "### **Improving Matrix Factorization based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQcDPhhcnVNN"
   },
   "source": [
    "Below we will be tuning only three hyperparameters:\n",
    "- **n_epochs**: The number of iterations of the SGD algorithm.\n",
    "- **lr_all**: The learning rate for all parameters.\n",
    "- **reg_all**: The regularization term for all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bM81V_hvtwv"
   },
   "outputs": [],
   "source": [
    "# Set the parameter space to tune\n",
    "param_grid = {\n",
    "    'n_epochs': [10, 20, 30],\n",
    "    'lr_all': [0.001, 0.005, 0.01],\n",
    "    'reg_all': [0.2, 0.4, 0.6]\n",
    "}\n",
    "\n",
    "# Performing 3-fold gridsearch cross-validation\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Fitting data\n",
    "gs.fit(data)\n",
    "\n",
    "# Best RMSE score\n",
    "print('Best RMSE score:', gs.best_score['rmse'])\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "print('Best parameters:', gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzY78HsrnVNO"
   },
   "source": [
    "Now, we will **the build final model** by using **tuned values** of the hyperparameters, which we received using grid search cross-validation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TA_7xe-nnhuu"
   },
   "outputs": [],
   "source": [
    "# Build the optimized SVD model using optimal hyperparameter search. Use random_state=1\n",
    "best_params = gs.best_params['rmse']\n",
    "optimized_svd = SVD(n_epochs=best_params['n_epochs'], lr_all=best_params['lr_all'],\n",
    "                    reg_all=best_params['reg_all'], random_state=1)\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "optimized_svd.fit(trainset)\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "precision_recall_at_k(optimized_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HJvPsjITsny"
   },
   "source": [
    "Observations: Compared to the previous svd algorithm (model 3) - untuned - the RMSE is lower which is a good sign. The precision is higher than 0.853 which is also a good sign. F1_score has remained the same for both. Recall has decreased however by 0.002."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A34BZM6S9L7QI4\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use svd_algo_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "prediction_A3 = optimized_svd.predict(\"A3LDPF5FMB782Z\", \"1400501466\")\n",
    "print(\"Predicted rating for A3LDPF5FMB782Z on product 1400501466:\", prediction_A3.est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use svd_algo_optimized model to recommend for userId \"A34BZM6S9L7QI4\" and productId \"1400501466\"\n",
    "prediction_A34 = optimized_svd.predict(\"A34BZM6S9L7QI4\", \"1400501466\")\n",
    "print(\"Predicted rating for A34BZM6S9L7QI4 on product 1400501466:\", prediction_A34.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: The prediction of the first user here is greater than the baseline model. The prediction of the second user is lower than the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnwPwgjB8DwS"
   },
   "source": [
    "### **Conclusion and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuqnifw9NF2p"
   },
   "source": [
    "In this case study, we built recommendation systems using the following different algorithms.\n",
    "\n",
    "Rank-based using averages\n",
    "\n",
    "User-user-similarity-based collaborative filtering\n",
    "\n",
    "Item-item-similarity-based collaborative filtering\n",
    "\n",
    "Model-based (matrix factorization) collaborative filtering\n",
    "\n",
    "We have seen how they are different from each other and what kind of data is needed to build each of these recommendation systems. We can further combine all the recommendation techniques we have seen.\n",
    "\n",
    "To demonstrate \"user-user-similarity-based collaborative filtering\",\"item-item-similarity-based collaborative filtering\", and \"model-based (matrix factorization) collaborative filtering\", surprise library has been introduced. For these algorithms grid search cross-validation is applied to find the best working model, and using that the corresponding predictions are done.\n",
    "\n",
    "For performance evaluation of these models precision@k and recall@k are introduced in this case study. Using these two metrics F_1 score is calculated for each working model.\n",
    "\n",
    "High precision means that an algorithm returned substantially more relevant results than irrelevant ones, with few false positives. If you raise the threshold for classifying a positive case, you’ll typically increase precision but might decrease recall. Precision is impacted when there is a change in the number of false positives. If false positives increase, precision decreases.\n",
    "\n",
    "High recall means that an algorithm returned most of the relevant results, with few false negatives. If you lower the threshold for classifying a positive case, you’ll typically increase recall but might also increase the false positives, thus lowering precision. Recall is impacted when there is a change in the number of false negatives. If false negatives increase, recall decreases.\n",
    "\n",
    "Hence all in all, following are the obtained prediction statistics for each model:\n",
    "\n",
    "RMSE: 1.0012 Precision: 0.855 Recall: 0.858 F_1 score: 0.856\n",
    "\n",
    "RMSE: 0.9523 Precision: 0.849 Recall: 0.892 F_1 score: 0.87\n",
    "\n",
    "RMSE: 0.9950 Precision: 0.838 Recall: 0.845 F_1 score: 0.841\n",
    "\n",
    "RMSE: 0.9578 Precision: 0.839 Recall: 0.88 F_1 score: 0.859\n",
    "\n",
    "RMSE: 0.8882 Precision: 0.853 Recall: 0.88 F_1 score: 0.866\n",
    "\n",
    "RMSE: 0.8808 Precision: 0.854 Recall: 0.878 F_1 score: 0.866\n",
    "\n",
    "Recommendation: Model 3 with tuned values and RMSE 0.8808 has the lowest RMSE, which is good. The same model with RMSE 0.8808 also has high precision (0.854), recall (0.878), and F_1 score (0.866).This model has a good balance between all four metrics, making it the most optimal among others. It has the lowest error and still maintains high precision, recall, and F_1 score, which means it's accurate and reliable in its recommendations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
